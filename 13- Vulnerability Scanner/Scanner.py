import urllib.parse
import requests
import re

class Scanner:
    def __init__(self, url):
        self.session = requests.Session()
        self.target_url = url
        self.target_links = []

    def extract_links(self, url):
        response = self.session.get(url)
        try:
            # response.content'i ISO-8859-1 formatında bir stringe çevir
            content = response.content.decode('iso-8859-1')
        except UnicodeDecodeError:
            # Eğer ISO-8859-1 ile çözümlenemiyorsa, alternatif bir kodlama kullan
            content = response.content.decode('utf-8', errors='replace')
        return re.findall('(?:href=")(.*?)"', content)

    def crawl(self, url=None):
        if url is None:
            url = self.target_url
        href_links = self.extract_links(url)
        for link in href_links:
            link = urllib.parse.urljoin(url, link)

            if '#' in link:
                link = link.split('#')[0]

            if self.target_url in link and link not in self.target_links:
                self.target_links.append(link)
                print(link)
                self.crawl(link)
